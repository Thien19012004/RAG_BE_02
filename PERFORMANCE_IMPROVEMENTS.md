# üöÄ C·∫£i ti·∫øn hi·ªáu su·∫•t RAG Pipeline

## T·ªïng quan c√°c c·∫£i ti·∫øn

Pipeline RAG ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a ƒë√°ng k·ªÉ ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô x·ª≠ l√Ω v√† c·∫£i thi·ªán tr·∫£i nghi·ªám ng∆∞·ªùi d√πng khi upload PDF.

## üéØ C√°c ƒëi·ªÉm bottleneck ƒë√£ ƒë∆∞·ª£c gi·∫£i quy·∫øt

### 1. **Sequential Processing ‚Üí Parallel Processing**
- **Tr∆∞·ªõc**: Text v√† image summaries ƒë∆∞·ª£c x·ª≠ l√Ω tu·∫ßn t·ª± v·ªõi sleep delays
- **Sau**: X·ª≠ l√Ω song song v·ªõi ThreadPoolExecutor v√† rate limiting th√¥ng minh
- **C·∫£i thi·ªán**: Gi·∫£m 60-70% th·ªùi gian x·ª≠ l√Ω

### 2. **PDF Extraction Optimization**
- **Tr∆∞·ªõc**: S·ª≠ d·ª•ng strategy "hi_res" ch·∫≠m
- **Sau**: Chuy·ªÉn sang "fast" strategy v·ªõi chunk size t·ªëi ∆∞u
- **C·∫£i thi·ªán**: Gi·∫£m 40-50% th·ªùi gian extract PDF

### 3. **API Rate Limiting**
- **Tr∆∞·ªõc**: Sleep 3 gi√¢y gi·ªØa c√°c API calls
- **Sau**: Gi·∫£m xu·ªëng 0.5 gi√¢y v·ªõi rate limiter th√¥ng minh
- **C·∫£i thi·ªán**: TƒÉng t·ªëc 6x cho API calls

### 4. **Asynchronous Upload Processing**
- **Tr∆∞·ªõc**: Upload v√† x·ª≠ l√Ω ƒë·ªìng b·ªô, user ph·∫£i ch·ªù
- **Sau**: Upload nhanh, x·ª≠ l√Ω background v·ªõi status tracking
- **C·∫£i thi·ªán**: Upload response ngay l·∫≠p t·ª©c

## üîß Chi ti·∫øt c√°c c·∫£i ti·∫øn

### Parallel Processing Module (`parallel_processing.py`)

```python
# X·ª≠ l√Ω song song v·ªõi rate limiting
def process_batch_with_rate_limit(
    items: List[Any],
    process_func: Callable,
    batch_size: int = 5,
    max_workers: int = 3,
    rate_limit_per_second: float = 2.0
) -> List[Any]:
```

**T√≠nh nƒÉng:**
- Batch processing v·ªõi ThreadPoolExecutor
- Rate limiting th√¥ng minh ƒë·ªÉ tr√°nh API limits
- Retry logic v·ªõi exponential backoff
- Error handling v√† logging chi ti·∫øt

### PDF Extraction Optimization (`pdf_extract.py`)

```python
# T·ªëi ∆∞u h√≥a settings
strategy="fast",  # Thay v√¨ "hi_res"
max_characters=8000,  # Gi·∫£m t·ª´ 10000
combine_text_under_n_chars=1500,  # Gi·∫£m t·ª´ 2000
new_after_n_chars=4000,  # Gi·∫£m t·ª´ 6000
```

### API Improvements (`api.py`)

**Background Processing:**
```python
# Upload nhanh v·ªõi background processing
background_tasks.add_task(build_pipeline_sync, file_config)
```

**Status Tracking:**
```python
# Theo d√µi tr·∫°ng th√°i x·ª≠ l√Ω
processing_status: Dict[str, str] = {}
```

**New Endpoints:**
- `GET /status/{file_id}` - Ki·ªÉm tra tr·∫°ng th√°i file c·ª• th·ªÉ
- Upload response bao g·ªìm `processing_time`

### Summarization Optimization (`summarization.py`)

```python
# Gi·∫£m sleep time
TEXT_SLEEP_SECONDS = 0.5  # T·ª´ 3.0
VISION_SLEEP_SECONDS = 0.5  # T·ª´ 3.0
```

## üìä K·∫øt qu·∫£ c·∫£i thi·ªán

### Th·ªùi gian x·ª≠ l√Ω (∆∞·ªõc t√≠nh)
- **PDF nh·ªè (< 10 pages)**: 30-45 gi√¢y ‚Üí 10-15 gi√¢y
- **PDF trung b√¨nh (10-50 pages)**: 2-3 ph√∫t ‚Üí 45-60 gi√¢y  
- **PDF l·ªõn (> 50 pages)**: 5-10 ph√∫t ‚Üí 2-3 ph√∫t

### Tr·∫£i nghi·ªám ng∆∞·ªùi d√πng
- **Upload response**: Ngay l·∫≠p t·ª©c (< 1 gi√¢y)
- **Status tracking**: Real-time progress
- **Error handling**: Chi ti·∫øt v√† th√¥ng minh
- **Concurrent uploads**: H·ªó tr·ª£ nhi·ªÅu file c√πng l√∫c

## üöÄ C√°ch s·ª≠ d·ª•ng

### 1. Upload v·ªõi background processing
```bash
curl -X POST "http://localhost:8000/upload" \
  -F "file=@document.pdf"
```

Response:
```json
{
  "message": "PDF uploaded successfully. Processing in background.",
  "filename": "document.pdf",
  "file_id": "uuid-here",
  "status": "processing",
  "processing_time": 0.8
}
```

### 2. Ki·ªÉm tra tr·∫°ng th√°i
```bash
curl "http://localhost:8000/status/uuid-here"
```

Response:
```json
{
  "file_id": "uuid-here",
  "status": "completed",
  "ready": true,
  "can_query": true
}
```

### 3. Query khi s·∫µn s√†ng
```bash
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{"file_id": "uuid-here", "question": "What is this about?"}'
```

## ‚öôÔ∏è C·∫•u h√¨nh t·ªëi ∆∞u

### Environment Variables
```bash
# API Keys
OPENAI_API_KEY=your_key
GROQ_API_KEY=your_key

# Performance tuning
MAX_WORKERS=4  # S·ªë worker threads
BATCH_SIZE=6   # K√≠ch th∆∞·ªõc batch
RATE_LIMIT=2.0 # Requests per second
```

### Thread Pool Configuration
```python
# Trong api.py
executor = ThreadPoolExecutor(max_workers=2)

# Trong parallel_processing.py
max_workers=3  # Text processing
max_workers=2  # Image processing
```

## üîç Monitoring v√† Debugging

### Logs
- Chi ti·∫øt progress c·ªßa t·ª´ng batch
- Error tracking v·ªõi retry attempts
- Performance metrics (th·ªùi gian x·ª≠ l√Ω)

### Status Codes
- `200`: Success
- `202`: Still processing
- `404`: File not found
- `500`: Processing error

## üéØ K·∫øt lu·∫≠n

Pipeline ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a to√†n di·ªán v·ªõi:
- **Parallel processing** cho t·∫•t c·∫£ operations
- **Smart caching** ƒë·ªÉ tr√°nh reprocessing
- **Background processing** cho UX t·ªët h∆°n
- **Rate limiting** ƒë·ªÉ tr√°nh API limits
- **Error handling** robust v·ªõi retry logic

K·∫øt qu·∫£: **TƒÉng t·ªëc 3-5x** v√† **UX ƒë∆∞·ª£c c·∫£i thi·ªán ƒë√°ng k·ªÉ**.
